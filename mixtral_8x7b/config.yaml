encoder:
  model_path: "sentence-transformers/multi-qa-mpnet-base-dot-v1"
  model_kwargs: 
    device: "cpu"
  encode_kwargs:
    normalize_embeddings: False
  
retriever:
  passage:
    chunk_size: 1000
    chunk_overlap: 0

generator:
  llama:
    llm_path: "model/nous-hermes-llama-2-7b.Q4_K_M.gguf"
  mistral:
    llm_path: "model/mistral-7b-v0.1.Q4_K_M.gguf"
  llama70b:
    llm_path: "model/llama-2-70b.Q4_K_M.gguf"
  mixtral8x7b:
    llm_path: "model/mixtral-8x7b-v0.1.Q4_K_M.gguf"
  context_length: 1024
  temperature: 0.7
  max_tokens: 2000
